---
layout: archive
title: "Research Interests & Projects"
permalink: /research/
author_profile: true
---

### [Current Projects](#current-projects) &nbsp;&nbsp;&nbsp; [Previous Projects](#previous-projects)  &nbsp;&nbsp;&nbsp; [Collaborators](#collaborators) 

Current Projects
------

1. **<font color='#b300b3'>Speech Activity Detection for Prompted Pre-School Children Speech</font>** (PIs: [Dr. John H.L. Hansen](https://personal.utdallas.edu/~john.hansen/), [Dr. Thomas F. Campbell](https://utdallas.edu/chairs/profiles/dr-thomas-campbell/)):<br>
Details coming soon !


2. **<font color='#009933'>Sequential Pattern Learning in children with Developmental Language Disorder</font>** (PI: [Dr. Lisa Goffman](https://utdallas.edu/chairs/profiles/dr-lisa-goffman/)):   
Developmental language disorder (DLD; aka specific language impairment) affects approximately 7% of children at the time they enter kindergarten, with longstanding adverse academic, social, and communicative consequences. While there is no question that language deficits feature prominently in children diagnosed with DLD, there are other cognitive and motor capacities affected—such as pattern induction, rhythmic grouping, and sequential organization. Previous findings show that the capacity for deploying sequentially patterned information mediates language and motor production. Sequential patterning is a central component of phonology and morphosyntax–domains of language difficulty presented in children with DLD.  The central aim of this project is to implement a novel framework for applying domain general cognitive mechanisms to learning and generalization; specifically all of the proposed experiments have in common the hypothesis that children with DLD will learn more effectively and generalize more broadly when targets are selected to emphasize the regularity of sequential patterns.

Previous Projects
------

1. **<font color='#994d00'>Articulatory Kinematic Analysis of subjects with Amyotrophic Lateral Sclerosis</font>** (PI: [Dr. Jun Wang](https://csd.utexas.edu/faculty/jun-wang)):<br>
Amyotrophic lateral sclerosis (ALS) is a progressive neurodegenerative disease that severely impairs voluntary motor function. As ALS progresses, patients will experience loss of motor control including difficulties to maintain speech and swallowing abilities. Accurate detection and monitoring of ALS are critical for effective therapeutic intervention. Recent studies discovered that the articulatory subsystem was most sensitive to ALS for monitoring speech performance decline and predicted that the speed of the tongue might be particularly sensitive to early changes in speech motor performance. Research suggests that articulatory kinematics may be beneficial for earlier diagnosis of ALS. This project was motivated by the need to develop more sensitive markers of disease progression for subjects with ALS which will improve current clinical practise. \[Journal in review\]

1. **<font color='#994d00'>Articulatory Kinematic Analysis of subjects with Laryngectomy vs. Silent Speech</font>** (PI: [Dr. Jun Wang](https://csd.utexas.edu/faculty/jun-wang)):    
Laryngectomy is the surgical removal of a larynx due to oral or laryngeal cancer. After the larynx is removed, the articulatory control system cannot modify the length of the vocal tract based on larynx height and the patients lose the ability to control pitch. To overcome limitations of available voice prosthesis options, studies have focused on the development of silent speech interface (SSI) technology which allows for communication without the vibration of the vocal folds. Specifically, SSIs convert articulatory motion data to an acoustic output. A better understanding of alaryngeal speech is needed to advance scientific knowledge of motor control and for the development of SSI technology. The aim of this study was to characterize articulatory movements during the production of phrases obtained from healthy (voiced, silent) speakers and laryngectomees. In addition, a support vector machine (SVM) model was used to classify the three speech modes based on tongue and lip motion patterns.  \[[Poster](https://satwikdutta.github.io/files/2020_MotorSpeech.pdf)\]

1. **<font color='#994d00'>Real-Time Voice Activity Detection from Non-Invasive Neuromagnetic (MEG) Signals</font>** (PI: [Dr. Jun Wang](https://csd.utexas.edu/faculty/jun-wang)):    
Neural speech decoding-driven brain-computer interface (BCI) or speech-BCI is a novel paradigm for exploring communication restoration for locked-in (fully paralyzed but aware) patients. Speech-BCIs aim to map a direct transformation from neural signals to text or speech, which has the potential for a higher communication rate than the current BCIs. Although recent progress has demonstrated the potential of speech-BCIs from either invasive or non-invasive neural signals, the majority of the systems developed so far still assume knowing the onset and offset of the speech utterances within the continuous neural recordings. To address this issue, in this study, an attempt was made to automatically detect the voice/speech activity directly from the neural signals recorded using magnetoencephalography (MEG) using long short-term memory-recurrent neural networks (LSTM-RNN). \[[Journal](https://doi.org/10.3390/s20082248)\]


Collaborators
------

* Dr. John H.L. Hansen, University of Texas at Dallas, USA.
* Dr. Lisa Goffman, University of Texas at Dallas, USA.
* Dr. Thomas F. Campbell, University of Texas at Dallas, USA.
* Dr. Jun Wang, University of Texas at Austin, USA.
* Dr. Sebastian Helie, Purdue University, USA. 
* Dr. Christine A. Dollaghan, University of Texas at Dallas, USA. 
* Dr. Johanna Rudolph, University of Texas at Dallas, USA. 
* Dr. Alan Wisler, University of Texas at Austin, USA.
* Prasanna V. Kothalkar, University of Texas at Dallas, USA.
* Kathryn Kreidler, University of Texas at Dallas, USA.
* Leah Sack, University of Texas at Dallas, USA.
* Kristin Teplansky, University of Texas at Austin, USA.
* Debadatta Dash, University of Texas at Austin, USA.
